# Obtaining Predictive Distributions for Reserves Which Incorporate Expert Opinions - R. Verrall

Know how the model is defined with ODP and ODNB and stochastic row parameters

Know the Bayesian BF calculation and assumptions \@ref(eq:bayesian-bf-verrall) and \@ref(eq:verall-bf-cred-fact)

Know how to [use](#stoch-col-bf) and [calculate](#verrall-gamma-calc) the stochastic column parameters

## Introduction

Uses Bayesian techniques to allow incorporation of expert opinion and also maintain the integrity of the prediction error

* i.e. how expert opinion from sources other than the specific data set under consideration can be incorporated into the predictive distributions of the reserves

* Take into account prior knowledge in setting reserves

    e.g. Adjusting data to reflect changes in benefits or claims handling, or select *L*-year average LDFs

* Calculating prediction error using prior knowledge

* Use Bayesian to take into account our a-priori and the strength of that a-priori (credibility)

Paper focus on use of a-priori knowledge for LDF selection and *BF* Method

Development of MCMC techniques has made Bayesian methods much easier

* Makes it easier to find the **posterior distributions** for future observations (defining the Bayesian model is always easy)

* MCMC breaks down the simulation process into a number of simulations that are easy to carry out

    $\therefore$ This solves the common Bayesian problem of difficulty in finding the posterior distribution (as they can be multidimensional)
    
* MCMC doesn't simulate all the parameters at once, it use the conditional distribution of each parameter, given all the others

    $\therefore$ Reducing the simulation to a univariate distribution
    
* Markov chain is formed because each parameter is considered in turn, and it is a simulation-based method

    $\therefore$ MCMC
    
### Notation {#verrall-notation}

For a $n \times n$ triangle

**Claims**

* Incremental claims for AY $i$ and age $j$: $c_{ij}$

$$\{ c_{ij} \: : \: j=1,...,n-i+1 \: ; \: i = 1,...,n \}$$

* Cumulative claims

$$D_{ij} = \sum_{k=1}^j c_{ik}$$

* Ultimate losses

$$D_{in} = \sum_{k=1}^n c_{ik}$$

```{remark}
We only consider forecasting losses up to the latest development year $n$

* It is possible to extend this to allow a tail factor but not in this paper
```

**Row Parameters**

* Expected ultimate losses for AY $i$: $x_i$

$$x_i = \mathrm{E}[D_{in}]$$

**Column Parameters**

* Expected % reported in each period: $y_j$

    $\sum y_i = 1$

* Expected reported to date: $p_j$

    $\sum_{k=1}^j y_k$

* Expected development from $D_{ij-1}$ to $D_{ij}$: $\lambda_j$ ($= \dfrac{p_j}{p_{j-1}}$?)

$$\{\lambda_j \: : \: j = 2 ,...,n\}$$

* Weighted average LDFs: $\hat{\lambda}_j$

$$\hat{\lambda}_j = \dfrac{\sum_{i=1}^{n-j+1} D_{ij}}{\sum_{i=1}^{n-j+1} D_{ij-1}}$$

## Stochastic Models for the Chainladder

Stochastic models that have the same estimate of Unpaid losses as the Chainladder

For each model, we can calculate the MSE of prediction and therefore a prediction interval

```{proposition}
Prediction variance = process variance + estimation variance
```

```{proof}
$$\begin{array}
\text{MSEP} &= &\mathrm{E}[(y - \hat{y})^2] \\
&= &\mathrm{E}[((y-\mathrm{E}[y]) - (\hat{y} - \mathrm{E}[y]))^2] \\
&\approx &\mathrm{E}[((y-\mathrm{E}[y]) - (\hat{y} - \mathrm{E}[\hat{y}]))^2] \\
&= &\mathrm{E}[(y - \mathrm{E}[y])^2] \\
& &-2\mathrm{E}[(y-\mathrm{E}[y])(\hat{y} - \mathrm{E}[\hat{y}])] \\
& &+ \mathrm{E}[(\hat{y} - \mathrm{E}[\hat{y}])^2]\\
&= &\underbrace{\mathrm{E}[(y - \mathrm{E}[y])^2]}_{\text{Process Variance}}+ \underbrace{\mathrm{E}[(\hat{y} - \mathrm{E}[\hat{y}])^2]}_{\text{Estimation Variance}}\\
\end{array}$$
```

```{remark}


* Assume future observations are independent of past observations and the -2 term above goes to 0

* S.e. = $\sqrt{\text{Estimation Variance}}$

* Prediction error includes both the error in estimating our parameters and the process variance (inherent variability in the data being forecast)

* Both bootstrap and MCMC allows us to calculate the prediction error
```

### Mack-1993 (Non-parametric)

Only the first 2 moments of **cumulative claims** are specified

\begin{equation}
  \mathrm{E}[D_{ij}] = \lambda_j D_{ij-1}
  (\#eq:verrall-mack-mean)
\end{equation}

\begin{equation}
  \mathrm{Var}(D_{ij}) = \sigma^2_j D_{ij-1}
  (\#eq:verrall-mack-var)
\end{equation}

```{remark}


* Mean is the same as the Chainladder

* Variance is $\propto$ claims reported to date $D_{ij-1}$

    $\sigma^2_j$ has to be estimated separately from the development factors

* The simplicity of this allows the parameter estimate and prediction errors to be obtained from a spreadsheet

* Downside is that without specifying a distribution we don't get a predictive distribution
```

### Over-dispersed Poisson and Negative Binomial

Separate stream of research that focused on the use of GLM

**Incremental claims** distribution **OD Poisson**:

\begin{equation}
\begin{split}
& c_{ij} \mid c, \alpha, \beta, \varphi \sim  ODP(m_{ij}, \varphi m_{ij}) \\
& \mathrm{E}[c_{ij}] = m_{ij} \\
& \mathrm{Var}(c_ij) = \varphi m_{ij} \\
& \ln(m_{ij}) = c + \alpha_i + \beta_j \: ; \: \alpha_1 = \beta_1 = 0 
\end{split}
(\#eq:verall-odp)
\end{equation}

```{remark}


* Model result is the same as Chainladder

* $m_{ij}$ mathematically the same as the one defined in [Shapland](#odp-glm-para), we can not include the $c$ term and just use $\alpha_i$'s as the individual level parameters instead of having $\alpha_1 = 0$ and use the $alpha_i$'s as adjustments to the level parameter constant $c$

* This allows for calculating prediction error

```

**Alternative way** of writing ODP

\begin{equation}
\begin{split}
& c_{ij} \mid x,y, \varphi \sim  ODP(x_i y_j, \varphi x_i y_j) \\
& \sum_{k=1}^n y_k = 1 \\
& x = \{x_1, x_2,...,x_n\} \:\: \text{row parameters}\\
&x_i = \mathrm{E}[D_{in}] \:\: \text{Expected ultimate cumulative losses up to }n\\
& y = \{y_1, y_2,...,y_n\} \:\: \text{col parameters}\\
& y_i \:\: \text{Proportions of ultimate losses that emerge in each development year}
\end{split}
(\#eq:verall-odp-2)
\end{equation}

*Recall*:

\begin{equation}
\begin{split}
&X \sim \text{Poisson}(\mu) \\
&Y = \varphi X \sim ODP(\varphi \mu, \varphi^2 \mu)\\
\end{split}
(\#eq:verall-odp-recall)
\end{equation}

* Where $\varphi$ is typically > 1 $\therefore$ over-dispersed

* This can be extend to other distribution beyond Poisson

    e.g. see over-dispersed negative binomial below

We can get the same predictive distribution (as ODP) with ODNB

* ODNB also make the connection between ODP and Chainladder more apparent

**Incremental claims** distribution for **OD Negative Binomial**:

\begin{equation}
\begin{split}
& c_{ij} \mid D_{ij-1}, \lambda_j, \varphi \sim  ODNB \\
& \mathrm{E}[c_{ij}] = (\lambda_j - 1)D_{ij-1} \\
& \mathrm{Var}(c_ij) = \varphi \lambda_j \mathrm{E}[c_{ij}] \\
\end{split}
(\#eq:verall-odnb)
\end{equation}

**Cumulative claims** distribution for **OD Negative Binomial**:

\begin{equation}
\begin{split}
& D_{ij} \mid D_{ij-1}, \lambda_j, \varphi \sim  ODNB \\
& \mathrm{E}[c_{ij}] = \lambda_j D_{ij-1} \\
& \mathrm{Var}(c_ij) = \varphi (\lambda_j - 1) \mathrm{E}[c_{ij}] \\
\end{split}
(\#eq:verall-odnb-cum)
\end{equation}

```{remark}
For both ODP and ODNB

* Use a quasi-likelihood approach so that the loss data are not restricted to the positive integers

* Reserve estimates are the same as Chainladder

* Both are subject to the positivity constraints

    * It's apparent in the ODNB formula that the column sums must be positive or else we'll have development factor $\lambda_j < 1$ $\Rightarrow$ Varaiance to be negative

* Advantages (over Kremer):

    * Does not necessarily break down if there are negative incremental loss values
    
        *  In a strick sense, the model requires the incremental losses in a column to be positive otherwise it is more difficult to justify and interpret the inferences (but it doesn't necessarily break the model)
    
    * Gives the same reserve estimate as Chainladder
    
    * More stable than the log-normal model of Kremer
    
* Verrall suggest that model can be specified for either incremental or cumulative loss

* Advantage of the NB:

    * Form of the mean is the same as chainladder
    
* If we replace the NB and use normal instead we can deal with the problem of negative incremental claims (not discussed in paper)

```

## Incorporating Expert Opinion about the Development Factors

Intervene in the estimation of Chainladder factors

* Intervention in a development factor in a particular row

* How many years of data to use in the estimation

**Procedure**

Step 1. Use ODNB from \@ref(eq:verall-odnb) for our incremental claim distribution

Step 2. Choose prior distribution

* Prior distributions (e.g. gamma, log-normal, etc) are chosen so that the numerical procedures in software (i.e.g winBUGS) work as well as possible

* We just choose if we want a *strong* or *vague* prior

    * Vauge priors (i.e. large variances)
    
        * Closer to Bayesian Chainladder
        
        * Prediction error will be similar to CL or slightly larger
        
    * Strong priors (i.e. small variances)
    
        * We think prior means are appropriate
        
        * Prediction error will decrease

Examples below for a $n \times n$ triangle

### Reproduce the Chainladder

This is the form if we just want to have just a regular Chainladder

$$\begin{array}.
\lambda_{i,j} = \lambda_j & \text{for } &i = 1,2,...,n-+1 ;\\
& &j = 2,3,...,n\\
\end{array}$$

**Vague** prior distributions for

$$\lambda_j \:\: ; \:\:(j=2,3,...,n)$$

* Use vague prior so $\lambda_j$ is based on data

### Intervention in a development factor in particular rows

**Example expert opinion**: 2^nd^ development factor ($\lambda_3$, from col 2 to 3) should be 1.5 for the recent 3 years (i.e. row 8,9,10) while the others being the same

$$\begin{array}.
\lambda_{i,j} = \lambda_j & \text{for } &i = 1,2,...,n-+1 ;\\
& &j = 2,4,5,...,n\\
\lambda_{i,3} = \lambda_3 & \text{for } &i = 1,2,..,7 \\
\lambda_{8,3} = \lambda_{9,3} = \lambda_{10,3} \\
\end{array}$$

Prior distribution mean and variance is chosen to reflect the expert opinion

* $\lambda_{8,3}$ has prior distribution with *mean* 1.5 and *variance* $W$

    * $W$ is selected to reflect the **strength of the prior** information

* $\lambda_j$ have prior distributions with **large variances**

### Intervention in using L-years average

**Example expert opinion**: Use 5 years weighted average for LDF selection

We divide the data into 2 parts using the prior distributions:

\begin{equation}
\begin{array}.
\lambda_{i,j} = \lambda_j & \text{for } &i = n-j-3, n-j-2, n-j-1,\\
& &n-j, n-j+1\\
\lambda_{i,j} = \lambda_j^* & \text{for } &i = 1,2,...,n-j-4 \\
\end{array}
(\#eq:verall-5-year-avg-lambda)
\end{equation}

Both $\lambda_j$ and $\lambda_j^*$ have prior distributions with large variance so they are estimated from the data

The first part of the \@ref(eq:verall-5-year-avg-lambda) is to adjust for later development years where there are less than 5 rows

* For those columns there is just one development parameters $\lambda_j$

## Bayesian Model for the Bornhuetter-Ferguson Method

Use the ODP model from \@ref(eq:verall-odp-2)

For the *BF* there is expert opinion about the level of each row, so we'll specify the prior distribution for it below:

\begin{equation}
x_i \mid \alpha_i, \beta_i \sim \Gamma(\alpha_i, \beta_i) \:\: ; \:\: x_i \perp\!\!\!\!\perp x_j \:\: i \neq j
(\#eq:verall-bf-apriori)
\end{equation}

Easiest to consider the mean and variance of the gamma distribution to parameterize

\begin{equation}
  \mathrm{E}[x_i] = \dfrac{\alpha_i}{\beta_i} = M_i\\
  \mathrm{Var}(x_i) = \dfrac{\alpha_i}{\beta_i^2} = \dfrac{M_i}{\beta_i}\\
(\#eq:verall-gamma-apriori)
\end{equation}

* For a given choice of $M_i$, the variance can be altered by changing the value of $\beta_i$

* Larger $\beta_i$ means we are more sure about the value $M_i$ and vice versa

Now consider the effect of using these prior distributions on the model for the data, after some lengthy proof:

<!-- * Recall the mean for $c_{ij}$ from \@ref(eq:verall-odnb) -->

<!-- In a Bayesian context, we first derive the posterior distribution of the row parameters given the data -->

<!-- $$f(x_i \mid y; data) \propto f(data \mid x,y)\:f(x_i \mid \alpha_i, \beta_i)$$ -->

<!-- If we're considering $c_{ij}$ the $data$ used here is $c_{i1},...,c_{ij-1}$ -->

<!-- Having obtained this distribution, the distribution of the next observation can be found as: -->

<!-- $$f(c_{ij} \mid y; data) = \int f(c_{ij}\mid x_i, y)\:f(x_i \mid y; data) dx_i$$ -->

```{block, type='rmdnote'}
Important formulas below
```

\begin{equation}
\mathrm{E}[c_{ij}] = Z_{ij} \times \underbrace{(\lambda_j -1)D_{ij-1}}_{\text{Chainladder}} + (1 - Z_{ij}) \times \underbrace{M_i \: y_i}_{\text{BF}}
(\#eq:bayesian-bf-verrall)
\end{equation}

```{remark}


* Result is a blend of Chainladder and BF (like **Benktander**)

* $y_i = \dfrac{\lambda_j -1}{\lambda_j \lambda_{j+1} \cdots \lambda_n}$
```

**Credibility factor** $Z_{ij}$

\begin{equation}
Z_{ij} = \dfrac{p_{j-1}}{\beta_i \varphi + p_{j-1}}
(\#eq:verall-bf-cred-fact)
\end{equation}

```{remark}


* $p_{j-1} = \sum_{k=1}^{j-1} y_k$ (Mack notations), percentage paid at the prior age

    * Large $p_{j-1}$ means losses are more mature so more weight to the Chainladder method

* We can influence the balance of the weighting ($Z_{ij}$) through $\beta_i$

    * Larger $\beta_i$ the more weight goes to the *BF* method
    
    * Prior with large variance will give results close to Chainladder
    
        Lowers the prediction error but not by much
    
    * Prior with small variance will give results close to *BF*
    
        Will lower the prediction error due to low variance in the prior
    
* $\varphi$ the process variance on $c_{ij}$ also have impact on the credibililty

    * If there's more variability in the $c_{ij}$ then we trust the *BF* method more
```

### Calculation Example

**Given**

* Incremental paid triangle

* ODP mean and variance for every AYs

* Dispersion factor $\varphi$

**Procedure**

1. Covert triangle to cumulative and select LDFs

    (Use all year vol. wtd. average)

2. Calculate Cumulative LDFs and $p_j$ and $y_j$

3. Calculate Chainladder ultimate and use $y_i$ to calculate the incremental means for each of the future cells

4. Calculate a-priori mean based on the given ODP mean for each AY $\times$ $y_j$ for the incremental means for each of the future cells

5. Calculate $\beta_i$ for each AYs using $\beta_i = \dfrac{\mathrm{E}[x_i]}{\mathrm{Var}(x_i)}$

    * Note that the $\beta_i$'s are unit dependent so need to be consistent
    
6. Calculate $Z_{ij}$ with \@ref(eq:verall-bf-cred-fact) for each future cells

7. Finally credibility weight the Chainladder and *BF* estimates

## Stochastic Column Parameters for Bayesian BF {#stoch-col-bf}

*BF* above uses stochastic row parameters $x_i$ and deterministic column parameters (Vol. Wtd. average LDFs)

We can use stochastic process for both by first estimating the column parameters then the row parameters

* Define improper prior distribution for the column parameters *first* before applying prior distributions for the row parameters and estimating them

* This approach allows us to take into account the fact that the column parameters have been estimated when calculating the prediction errors, predictive distribution etc

* We don't have to include any information about the column parameters so we use improper gamma distribution (wide variance) for the column parameters

Result posterior distribution:

\begin{equation}
\begin{split}
& c_{ij} \mid c_{1,j}, c_{2,j},..., c_{i-1,j}, x, \varphi  \sim  ODNB \\
& \mathrm{E}[c_{ij}] = (\gamma_i - 1) \sum \limits_{m=1}^{i-1} c_{m,j} \\
\end{split}
(\#eq:verall-odnb-col-para)
\end{equation}

* Note that it is similar to \@ref(eq:verall-odnb) but recursive down the column (over $i$)

    * $\sum \downarrow$

* $\gamma_i$ is the new row parameters

    * This tells you the level of losses in the row relative to the rows above

```{r verall-stoch-para, echo = FALSE, out.width='75%', fig.show='hold', fig.cap='Stochastic Column Parameters'}
knitr::include_graphics('figures/Exam-7-Notes-2.png')
```

We now have a stochastic version of the *BF* method

* *BF* inserts values for the expected ultimate claims in each row, $x_i$, in the form of the values $M_i$

* In Bayesian context, prior distributions will be defined for the parameters $x_i$ as discussed above

* However, the model has been reparameterized with a new set of parameters $\gamma_i$

* Therefore it is necessary to define the relationship between the new parameters $\gamma_i$ and the original $x_i$

* Section [below](#verrall-gamma-calc) shows how to find $\gamma_i$ from the values of $x_i$ given in the prior distributions

Stochastic *BF* summary:

* Column parameters (LDFs) are dealt with first using improper prior

    Their estimates will be those implied by the Chainladder
    
* Prior information can be defined in terms of distributions for the parameters $x_i$, which can then be converted into values for the parameters $\gamma_i$

### Calculate Gamma {#verrall-gamma-calc}

Know how to calculate this pictorially (equation is complicated...)

First, use Chainladder to get ultimate loss and % unpaid by AY

$\gamma_1 = 1.000$

First calculate **LDFs**, then the **% unpaid** and **a-priori** for each *AY*

* $U_i$ = a-priori ultimate based on LDF for AY $i$

* $q_i$ = % unpaid for AY $i$

```{r verall-gamma-calc, echo = FALSE, out.width='100%', fig.show='hold', fig.cap='Calculating gamma'}
knitr::include_graphics('figures/Exam-7-Notes-3.png')
```

Note that in step 4 above if you don't need the individual cells you can just take the $U_3 q_3$

## Implementation

In a full Bayesian analysis, we should have a prior distribution for $\varphi$ as well

* But for ease of implementation, we'll use a plug in estimate

* Value used is that obtained from the application of the ODP, estimating the row and column parameters using MLE

The main thing is just picking how strong our prior is and it'll be more like Chainladder or *BF* depending on our prior

This section of the paper just goes through the methods we've discussed and comparing it to the no intervention Chainladder

## Past Exam Questions

```{block, type='rmdcaution'}
Haven't done TIA practice questions
```

**Concepts**

* 2012 #8: Explain model as trade off between standard CL and BF

* 2013 #9: Model specification stuff on variance of the prior, BF Bayesian

    * Bayesian vs Bootstrap: Provide expert opinion while maintaining the integrity of the variance estimates

    * Bayesian vs Mack: Provides full distribution of unpaid losses and not just the first 2 moments

* 2014 #10: Expert opinions in LDFs or row parameters; $\beta$ impact on the Bayesian model

**Full Calculation**

* $\star$ 2012 #8 \@ref(fig:2012-8): Bayesian model for BF method

### Question Highlights

```{r 2012-8, echo = FALSE, out.width='100%', fig.show='hold', fig.cap='2012 Question 8'}
knitr::include_graphics('questions/2012-8Q.png')
knitr::include_graphics('questions/2012-8A.png')
```
