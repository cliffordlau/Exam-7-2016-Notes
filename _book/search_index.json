[
["stochastic-loss-reserving-using-bayesian-mcmc-models-g-meyer.html", "Chapter 11 Stochastic Loss Reserving Using Bayesian MCMC Models - G. Meyer", " Chapter 11 Stochastic Loss Reserving Using Bayesian MCMC Models - G. Meyer Know how to read all the test: KS-test, \\(p-p\\) plot and Freq vs Count plot Know the form of all the methods in the model "],
["introduction-synopsis.html", "11.1 Introduction &amp; Synopsis", " 11.1 Introduction &amp; Synopsis Applying different estimate methods to 200 triangles and comparing the actual outcomes to the predicted distribution to see if the models accurately estimates the distribution of outcomes Models examined: Estimate from Mack and ODP do not have enough variability Incurred losses with variable row parameters and AY correlation \\(\\rho\\) is sufficient Paid losses requires variable row parameters and change in settlement rate parameter \\(\\gamma\\) Three reasons model doesn’t predict well: Insurance loss environment has experienced changes that are not observable at the valuation date i.e. There would be different “black swan” events that invalidate any attempt to model loss reserves There could be other models that better fit the existing data Data used to calibrate the model is missing crucial information needed to make a reliable prediction e.g. Changes in the way the underlying business is conducted, like changes in claim processes of changes in the direct/ceded/assumed reinsurance composition of the claims triangle If we can find better model and/or better data we can rule out 1) If we review many models and none of them validate it gives 1) credence but does not confirm "],
["data-set.html", "11.2 Data Set", " 11.2 Data Set 200 triangles from Sch P 1997 and reviewed 10 years later Paid and incurred 50 triangles from 4 LoB (Commercial Auto, Personal Auto, WC, Other Liab) Potential pitfalls in sample triangle selections Insurer with significant changes to their books over the exposure period would violate the assumptions of the model and should be excluded Solution: Use consisteny of NEP and Net:Gross Premium to establish stability in book Use CoV to establish consistency Pick triangles with CoV below a threshold Need to avoid selecting datasets that best suit the model e.g. removing “outliers” from the data Solution: Choose the company in an automated and well defined manner Losses are considered fully developed at 10 years so in practice the paid and incurred ultimate is slightly different "],
["meyers-test.html", "11.3 Testing Procedure", " 11.3 Testing Procedure We are testing the process of each method and not the results of any one distribution generated from the method Since there’s only 1 actual outcome for each triangle we test Focus on the process (the different methods) that gives us the distribution Compare the predicted percentiles (from the methods) against the expected percentile Testing Procedure Given \\(N\\) triangles and their actual outcome in 10 years Generate \\(N\\) sets of distribution (from the \\(N\\) triangles using one of the methods) and determine the predicted percentile \\(p_i\\) based on the predicted distribution i.e. see where the actual outcome lands on our predicted distribution The distribution of the \\(N\\) predicted percentiles \\(p_i\\) should follow a uniform distribution if the model is accurate, so we rank them to form \\(\\{p_i\\}\\) \\[\\{p_i\\} = \\{p_1,...,p_n\\}\\] The expected percentiles \\(\\{e_i\\}\\) should run from \\(\\frac{1}{n+1}\\) to \\(\\frac{n}{n+1}\\) \\[\\{e_i\\} = \\left\\{ \\dfrac{1}{n+1}, \\dfrac{2}{n+1},...,\\dfrac{n}{n+1} \\right\\}\\] 11.3.1 Kolmogorov-Smirnov Test For the KS test we’ll compare \\(\\{ p_i \\}\\) with \\(\\{ f_i \\}\\) \\[\\{f_i\\} = \\left\\{ \\dfrac{1}{n}, \\dfrac{2}{n},...,\\dfrac{n}{n} \\right\\}\\] \\(H_0\\): Distribution of \\(p_i\\) is uniform Test statistics for maximum difference between the predicted and expected percentiles \\[\\begin{equation} D = \\max \\limits_i \\mid p_i - e_i \\mid \\tag{11.1} \\end{equation}\\] Reject \\(H_0\\) @5% confidence level if: \\[\\begin{equation} D &gt; \\dfrac{136}{\\sqrt{n}}\\% \\tag{11.2} \\end{equation}\\] i.e. For \\(n = 50\\) \\(\\Rightarrow\\) 19.2%; \\(n=200\\) \\(\\Rightarrow\\) 9.6% Examples Table 11.1: Kolmogorov-Smirnov test example \\(f_i\\) \\(p_i\\) \\(abs\\{ p_i - f_i \\}\\) (1) (2) (3) Col (1): \\(\\{f_i\\} = \\left\\{ \\dfrac{1}{n},...,\\dfrac{n}{n}\\right\\}\\) Col (2): \\(\\{p_i\\}\\) = \\(p_i\\) from each realization of the triangles sorted in ascending order Col(3) = Absoluate difference between the first two columns \\(D\\) is the maximum value from column (3) Compare \\(D\\) with \\(\\dfrac{136}{\\sqrt{N}}\\) If \\(D\\) is less than the critical value we do not reject the \\(H_0\\) that \\(\\{ p_i \\}\\) is uniform Remark. Technically based on Klugman you test against both: \\[\\{f^+_i\\} = \\left\\{ \\dfrac{1}{n}, \\dfrac{2}{n},...,\\dfrac{n}{n} \\right\\}\\] and \\[\\{f^-_i\\} = \\left\\{ \\dfrac{0}{n}, \\dfrac{2}{1},...,\\dfrac{n-1}{n} \\right\\}\\] Alternatively, we can use Anderson-Darling test that focuses on the tail But it failed all the models therefore we do not use it as it does not help in model comparison 11.3.2 p-p Plot We plot the \\(p-p\\) plot with \\(e_i\\) vs \\(p_i\\) to diagnosis Dark blueline is what is expected from uniform distribution Light blueline is the critical value for a given \\(n\\) from the KS test above Figure 11.1: p-p plot Model is too light tailed: Shallow slope near corner and steep in the middle Model is too heavy tailed: Steep slope near corner and shallow in the middle Model is biased upwards: Bow down 11.3.3 Percentile Histogram We plot a (flipped) histogram y-axis being the predicted percentile x-axis is the frequency Bins with width 0.1 (so 10 bins) Verticle blue line represent the expected freqency based on uniform \\(\\{e_i\\}\\) Expected frequency = \\(\\dfrac{\\text{# of points}}{\\text{# of bins}}\\)= \\(\\dfrac{n}{10}\\) Figure 11.2: Percentile Histogram "],
["model-summary-meyers.html", "11.4 Models Comparison Summary", " 11.4 Models Comparison Summary 7 models: Mack: See Mack-1994 England &amp; Verall ODP: See Shapland, but doesn’t have the residual adjustments Leveled Chain-Ladder (LCL): Add variability to the row parameter Correlated Chain-Ladder (CCL): Add AY correlation \\(\\rho\\) Leveled Incremental Trend (LIT): Use skewed distribution and CY trend \\(\\tau\\) Correlated Incremental Trend (CIT): LIT with added AY correlation \\(rho\\) Changing Settlement Rate (CSR): LCL with speed up claims closure \\(\\gamma\\) Figure 11.3: Overview of models Mack is the only one that does not have a base form of \\(\\mu_{wd} = \\alpha_w + \\beta_d\\) ODP is the England &amp; Verall Bootstrap 11.4.1 Mack Model See procedure from Mack-1994 on the log-normal CI Variance is the product of mean in the cell and a constant that varies by column \\(\\operatorname{Var}\\left (c_{i,k+1} \\mid c_{i,1} \\cdots c_{i,k}\\right ) = \\alpha_k^2 \\: c_{i,k}\\) Incurred Light on both tail \\(\\Rightarrow\\) Does not have enough variability in it’s predicted distribution Paid Similar to ODP, biased high on personal auto and light left tail on WC 11.4.2 ODP Bootstrap EV ODP forecasts log incremental losses \\(\\Rightarrow\\) Only suitable for paid losses Can handle occasional negative losses as long as the \\(\\sum\\) column is positive Same procedure as Shapland Leong paper Overall shows biased high "],
["bayesian-models-cumulative.html", "11.5 Bayesian Models (Cumulative)", " 11.5 Bayesian Models (Cumulative) Inputs Prior distribution is needed for each parameters Wide priors (diffuse) Narrow priors: Use expert knowledge in selecting mean and variance of the parameters Parameters: \\(\\alpha_w\\): row parameters \\(\\beta_d\\): column parameters \\(\\sigma_d\\): variance parameters (mostly constant across columns) \\(\\tau\\): trend \\(\\gamma\\): change in closure rate Data: Paid or incurred Triangle Output The posterior distribution of the parameters is expressed as simulated outputs (not closed form distribution) 11.5.1 Leveled Chain Ladder LCL with incurred data Multiplicative model (based on additive exponential) Each cell is \\(e^{\\mu_{wd}} = e^{\\alpha_w}e^{\\beta_d}\\) Log mean of each cell is \\(\\mu_{wd} = \\alpha_w + \\beta_d\\) \\(\\beta_{10} = 0\\) so we have 100% at 10 years \\(\\beta_d &lt; 0\\) most of the time, represents % paid to date Uses cumulative data \\(C_{wd}\\) Same variance parameter (\\(\\sigma_d\\)) for each column of cumulative loss \\(\\hookrightarrow\\) Highest variability @ early ages \\(\\sigma_1 &gt; \\sigma_2 &gt; \\cdots &gt; \\sigma_{10}\\) Variance varies by column only (not by AYs) \\(\\alpha_w\\) is a random variable Not value on the diagonal (incurred to date) Model select an \\(\\alpha_w\\) for each instance of the simulation based on wide priors Main feature of this model for adding variability Can compare the variability (s.d.) with Mack by plotting the log(s.d.) of the 2 models Model still does not capture the tail appropriately 11.5.2 Correlated Chain-Ladder Build upon the Leveled Chain-Ladder by adding \\(\\rho\\) to create correlation of losses in one AY and the previous AY Uses cumulative data \\(C_{wd}\\) \\(\\mu_{wd} = \\alpha_w + \\beta_p + \\rho \\cdot \\left[ \\operatorname{ln}\\left(C_{w-1, d}\\right) - \\mu_{w-1,d} \\right]\\) Higher losses in one row \\(\\rightarrow\\) higher expected losses in the following row Prior is still wide priors The correlation here is what drives the additional variability Incurred Results and k-s test show that this model is sufficient Paid Worst than ODP and Mack, biased high for all lines 11.5.3 Changing Settlement Rate Based on LCL with \\(\\gamma\\) that allows for speed up in claim payments Uses cumulative losses Logmean for each cell: \\(\\mu_{wd} = \\alpha_w + \\left[ \\beta_d \\cdot (1-\\gamma)^{w-1}\\right]\\) \\(\\gamma &gt;0\\) reflects increase in payment speed as \\((1-\\gamma)^{w-1} &lt; 1\\) \\(\\gamma\\) has less impact further out in the tail as there are less payments happening out there Model fits one \\(\\gamma\\) for the whole triangle Results Overall fits well, slightly biased high on Personal Auto but is a big improvement over the other models "],
["skewed-distribution.html", "11.6 Skewed Distribution", " 11.6 Skewed Distribution Use incremental data as trends act on incremental loss, which has the following properties: Skewed right Occasionally negative 11.6.1 Skewed Normal Distribution Blend of normal and truncated normal \\(X = \\mu + (\\omega \\cdot Z) \\cdot \\delta + (\\omega \\cdot \\varepsilon) \\cdot \\sqrt{1 - \\delta^2}\\) \\(\\varepsilon \\sim Normal(0,1)\\) \\(Z \\sim Truncated \\: Normal_{[0,\\infty]} (0,1)\\) \\(\\delta\\) is the weight between \\(\\varepsilon\\) and \\(Z\\) \\(\\omega\\) is the standard deviation Skewness = 0.995; Not used by the Meyers as it is not skewed enough 11.6.2 Mixed Lognormal-Normal \\(X \\sim Normal(Z,\\delta)\\) \\(Z \\sim Lognormal(\\mu,\\sigma)\\) Mixed \\(ln - n\\) Distribution This can create distribution more skew than the skewed normal and can also have negative values "],
["bayesian-models-incremental.html", "11.7 Bayesian Models (Incremental)", " 11.7 Bayesian Models (Incremental) Model applies trend and therefore uses incremental data Correlated Incremental Trend Model Changing Settlement Rate Model 11.7.1 Correlated Incremental Trend Single CY trend parameter \\(\\tau\\) Mixed lognormal-normal distribution Include correlation between AY similar to CCL method Steps for the method: Uncorrelated log mean of each cell with CY trend \\(\\mu_{wd} = \\alpha_w + \\beta_d + \\tau \\cdot(w+d-1)\\) Draw \\(Z_{wd} \\sim Lognormal(\\mu_{wd},\\sigma_d)\\) \\(\\sigma_1 &gt; \\sigma_2 &gt; \\cdots &gt; \\sigma_{10}\\) Smaller less volatile claims should be settled early \\(\\tilde{I}_{wd} \\sim Normal(Z_{wd},\\delta)\\) Add correlation between AYs for rows after the first \\(\\tilde{I}_{wd} \\sim Normal(Z_{wd} + \\rho \\cdot (\\tilde{I}_{w-1,d} - Z_{w-1,d})\\cdot e^{\\tau},\\delta)\\) Parameters restrictions \\(\\tau\\): Prior \\(\\sim Normal(0,3.2%)\\) Without restriction it was forecasting very negative trend which is offset by higher \\(\\alpha\\) and \\(\\beta\\) \\(\\sigma_d\\): Prior \\(\\sigma_1 \\sim Uniform(0,0.5)\\) Prior \\(\\sigma_d \\sim Uniform(\\sigma^2_{d-1},\\sigma^2_{d-1} +0.1)\\) Limit the speed \\(\\sigma_d\\) can increase, very high \\(\\sigma_d\\) can lead to unreasonably high simulate results Results Losses not much smaller than CCL while we would like it to be much smaller as CCL was biased high \\(\\rho\\) is lower than from CCL Strong negative correlation between trend \\(\\tau\\) and level parameters \\(\\alpha_w + \\beta_d\\) With small data set it is hard for the model to distinguish the AY level + development vs trend Model showed no improvement over Mack or ODP 11.7.2 Leveled Incremental Trend Same as CIT but with \\(\\rho = 0\\) Results similar to CIT with lower standard deviation "],
["process-parameter-and-model-risk.html", "11.8 Process, Parameter, and Model Risk", " 11.8 Process, Parameter, and Model Risk \\(\\underbrace{\\text{Variance}}_{\\operatorname{Var}(X)} = \\underbrace{\\operatorname{E}[\\text{Process Variance}]}_{\\operatorname{E}_{\\theta}[\\operatorname{Var}[X|\\theta]]}+\\underbrace{\\operatorname{Var}[\\text{Hypothetical Mean}]}_{\\operatorname{Var}_{\\theta}[\\operatorname{E}[X|\\theta]]}\\) Typically the parameter risk is much larger than process risk Model risk is the risk of not selecting the right model For known unknown, weight average of multiple models If the weight vary a lot in the posterior distribution than this could be an indication of model risk This turns into more or less parameter risk Should focus on the total risk "],
["conclusion.html", "11.9 Conclusion", " 11.9 Conclusion Goal of the paper was to test the predictive accuracy of various models, both mean and distribution of outcomes Not on the reserve estimate for individual insurers 11.9.1 Results Summary Incurred Data Mack understates variability as it assumes AYs are independent CCL introduces AY correlation and does relatively well Paid Data Mack and ODP were biased high as well as CCL There were change in environment that is not captured Calendar year trend: LIT and CIT still biased high CSR: significantly less bias than LIT and CIT (except for PA still failed) Mack and ODP did better than CCL, LIT and CIT 11.9.2 Final Comments Results were for specific annual statement year 1997 Possible the speed up was specific to the period \\(\\Rightarrow\\) CSR could potentially useless for another year Could use more narrow prior to incorporate knowledge of insurer’s business operation and obtain superior results "],
["appendix-b-intro-to-bayesian-mcmc-models.html", "11.10 Appendix B: Intro to Bayesian MCMC Models", " 11.10 Appendix B: Intro to Bayesian MCMC Models Just additional background information, not part of exam syllabus Definition 11.1 Markov Chain Random process where the transition to the next state depends only on its current state and not on prior states A Markov chain \\(X_t\\) for \\(t=1,2,...\\) is a sequence of vectors satisfying the property that \\[\\Pr(X_{t+1} = x \\mid X_1 = x_1, X_2 = x_2,...,X_t = x_t) = \\Pr(X_{t+1} \\mid X_t = x_t)\\] Key properties of Markov chain ofr Bayesian MCMC Ergodic class of Markov chain, for which vectors \\(\\{X_t\\}\\) approaches a limiting distribution As \\(T\\) increases, the distribution of \\(\\{X_t\\}\\) for all \\(t&gt;T\\) approaches a unique limiting distribution Markov chains used in Bayesian MCMC (e.g. Metropolis Hastings algorithm) are members of Ergodic class Let \\(x\\) be a vector of observations and let \\(y\\) be a vector of parameters in a model In Bayesian MCMC, the Markov chain is defined in terms of the prior distribution \\(p(y)\\) and the conditional distribution \\(f(x \\mid y)\\) The limiting distribtuion is the posterior distribution \\(f(y \\mid x)\\) If we let the chain run long enough, the chain will randomly visit all states with frequency that is proportional to their posterior probabilities The operative phrase above is long enough, which means in practice: Develop algorithm for obtaining a chain that is long enough as quickly as possible Develop criteria for being long enough 11.10.1 How Bayesian MCMC works in practice User specifies \\(p(y)\\) and \\(f(x \\mid y)\\) User selects a starting vector \\(x_1\\) Using computer simulation, runs the Markov chain through a sufficiently large number, \\(t_1\\), of iterations This first phase of the simulation is called the “adaptive” phase The algorithm is automatically modified to increase its efficiency See below on the Metropolis-Hasting alogrithm User runs an additional \\(t_2\\) iterations This is the “burn-in” phase \\(t_2\\) is selected to be high enough so that a sample taken from subsequent \\(t_3\\) periods represents the posterior distribution User then runs an additional \\(t_3\\) iterations and then takes a sample, \\(\\{ x_t \\}\\) from the \\((t_2 + 1)\\)th step to the \\((t_2 + t_3)\\)th step to represent the posterior distribution \\(f(y \\mid x)\\) From the sample, we can constructs various statistics of interest that are relevant to the problem addressed by the analysis 11.10.2 Metropolis-Hastings Algorithm Most common algorithms for generating Bayesian Markov chains are variants of the Metropolis-Hastings algorithm Given: \\(p(y)\\) and \\(f(x \\mid y)\\) The algorithm introduces a 3rd distribution \\(J(y_t \\mid y_{t-1})\\): “Proposal” or “jumping” distribution Given a parameter vector \\(y_{t-1}\\) the algorithm generates a Markov chain by the following steps: Select a candiate value \\(y^*\\), at random from the proposal distribution \\(J(y_t \\mid y_{t-1})\\) Computer the ratio \\[R \\equiv R_1 \\times R_2 = \\dfrac{f(x \\mid y^*) \\cdot p(y^*)}{f(x \\mid y_{t-1}) \\cdot p(y_{t-1})} \\times \\dfrac{J(y_{t-1} \\mid y^*)}{J(y^* \\mid y_{t-1})}\\] Select \\(U\\) at random from \\(U(0,1)\\) distribution If \\(U &lt; R\\) then set \\(y_t = y^*\\), else \\(y_t = y_{t-1}\\) Remark. \\(R_1\\) represents the ratio of the posterior probability of the proposal \\(y^*\\) to the posterior probability of \\(y_{t-1}\\) The higher the value of \\(R_1\\), the more likely will be accepted into the chain Regardless of how the proposal density distribution is chosen, the distribution of \\(y_t\\) can be regarded as a sample from the posterior distribution, after a suitable burn-in period Example We can look at trace plots to look at the value of the parameter as the chain progresses More on how it might break in the paper… The key is to be able to scale the proposal distribution to minimize autocorrelation This is difficult with many parameters Minimizing autocorrelation in Metropolis-Hasting A good statistics to look at is the acceptance rate of \\(y^*\\) 50% is near optimal for a one parameter model and the rate decreases to about 25% as we increase the number of parameters in the model There are methods to automatically adjust the proposal density function in Metropolis-Hastins All these have been mechanized in software like JAGS and STAN The phase of generating the Markov chain where the proposal density function is optimized is called the “adaptive” state (as discussed above) As models become more complex, adaptive MCMC may not be good enough to eliminate the autocorrelation Theory on Markov chain convergence will still hold but there is no guarantee on how fast it will converge If there is significance autocorrelation after the best scaling effort, the next best practice is to increase \\(t_3\\) until there are sufficient number of ups and downs in the trace plot and then take a sample of the \\((t_1 + t_2 +1)\\)th to \\((t_1 + t_2 + t_3)\\)th iterations This process is known as “thinning” 11.10.3 Usecase Example for Actuaries Look at how the posterior distribution of \\(\\mu\\) might be of interest Consider a fitted lognormal distribution for a set of claims to determine the cost of an XS layer Given \\(\\mu\\) and \\(\\sigma\\) of the lognormal we can determine the cost of an XS layer (see Klugman, Panjer, and Willmot and the actuar package) As the posterior distribution of \\(\\mu\\) reflects the parameter risk in the model, it is also possible to reflect the parameter risk in the expected cost of a layer by calculating the expected cost of the layer for each \\(\\mu\\) in the simulated posterior distribution It is possible to simulate an actual outcome of a loss \\(X\\) in a layer given \\(\\mu\\) in the posterior distribution The distribution \\(X\\) calculated this way reflects both the parameter risk and process risk in the model 11.10.4 Bayesian interence Using Gibbs Sampling (BUGS) WinBUGS, JAGS are examples of software using Gibbs sampling Sample work process: Read data into R and call JAGS script with R package “runjags” Fetch the sample of the posterior back into R to calculate statistics of interest JAGS perform the Metropolis-Hasting algorithm we described above It also has a number of convergence diagnostics "],
["past-exam-questions.html", "11.11 Past Exam Questions", " 11.11 Past Exam Questions n/a 11.11.1 Question Highlights n/a -->"]
]
