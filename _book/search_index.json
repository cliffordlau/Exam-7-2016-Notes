[
["era-3-2-modeling-parameter-uncertainty-venter-gluck.html", "Chapter 23 ERA 3.2 Modeling Parameter Uncertainty - Venter, Gluck", " Chapter 23 ERA 3.2 Modeling Parameter Uncertainty - Venter, Gluck Parameter risk is more important as the process risk is smaller Different ways to model the severity trend Model the trend independently or adjust the general inflation then model the superimposed inflation Model with AR(1) Estimation risk in selecting the parameters and the downstream impact Use MLE working with negative log likelihood Slope of the negative log likelihood determines our confidence in the selection Use HQIC to adjust the loglikelihood with a penalty for # of parameters Also use a pool of distribution of reasonable parameters Form of the model we use to do the modeling e.g. expected parameters vs pool of distribution of parameters Should focus on the spread of potential outcomes instead of best estimate Add flexibility and let the parameters reflect the uncertainty in the assumptions "],
["era3-2-intro.html", "23.1 Introduction", " 23.1 Introduction Parameter risk is the risk inherent in selecting the wrong loss distribution Key for large companies since process risk is reduced with a large book Projection risk can be modeled using time series We can also measure estimation risk in parameter selection for a distribution Model risk is the uncertainty about the distribution of the parameters themselves Paper has 2 recommendations when using projection models "],
["impact-of-parameter-risk.html", "23.2 Impact of Parameter Risk", " 23.2 Impact of Parameter Risk CoV for total losses if the frequency and severity distribution are known \\[CV^2(S) = \\underbrace{CV^2(N)}_{\\text{# of Claims}} + \\underbrace{\\dfrac{CV^2(X)}{\\mu_N}}_{\\text{Severity}}\\] For large company, \\(\\mu_N\\) is large so the 2nd term is small \\(S\\) = Total losses \\(X\\) = Severity \\(N\\) = Numbers of claims However if we add systemic factor that impacts all claims (e.g. inflation), it doesn’t diversify away as the # of expected claims \\(\\uparrow\\) Relative impact on large company is much bigger since their process variance is small For small company there is a large amount of process risk so the overall variability does not increase very much "],
["projection-risk.html", "23.3 Projection Risk", " 23.3 Projection Risk Different ways to project trends Simple trend Severity trend and inflation Trend as time series 23.3.1 Simple Trend Forecast one trend using historical average and into the future Caveat: Additional uncertainty due to estimate of ultimate losses is uncertain 23.3.2 Severity Trend and Inflation Claim severity \\(\\neq\\) general inflation \\[[\\text{Claim Severity Trend}] \\approx [\\text{General Inflation}] + [\\text{Superimposed Inflation}]\\] 2 approaches: Model the severity trend independent of general inflation Adjust the data for general inflation and model the residual superimposed inflation For ERM where general inflation is modeled, severity trend should be dependent on the general inflation 23.3.3 Trend as a Time Series More realistic, allow for trends to change over time AR(1) with mean reverting form: \\[\\begin{array}{ccccc} r_{t+1} &amp;= &amp;m + \\alpha_1(r_t - m) &amp;+ &amp;\\epsilon_{t+1} \\\\ &amp;= &amp;(m - \\alpha_1 m) + \\alpha_1 r_t &amp;+ &amp;\\epsilon_{t+1} \\\\ &amp;= &amp;\\alpha_0 + \\alpha_1 r_t &amp;+ &amp;\\epsilon_{t+1} \\\\ \\end{array}\\] \\(m\\) is the long term mean estimated from data \\(\\alpha_1\\) is the correlation from one period to the next \\(\\epsilon_t \\sim N(0,\\sigma)\\) Simple trend understate the projection risk especially for long tail LoBs Simple trend had a 10 year forecast 99th percentile prediction error of +45% "],
["estimation-risk.html", "23.4 Estimation Risk", " 23.4 Estimation Risk Estimation risk is due to the uncertainty in selecting parameters (freq, sev, trend, variability) and specifically the downstream impact of this Maximum Likelihood Estimate For large data sets it has the lowest estimation error of unbiased estimators Uncertainty depends on the slop of the likelihood surface Steeper the slope near the MLE, the more confident we are in the estimate Measured by taking the 2nd derivative of the likelihood w.r.t. each parameters Negative of the 2nd derivative of the log likelihood = information matrix (easier to work with) \\[I = \\dfrac{\\partial^2 [\\overbrace{ -LL }^{\\text{Neg Log Likelihood}}]}{\\partial \\underbrace{\\vec{\\alpha}}_{\\text{Parameters}}}\\] Inverse of the information matrix = co-variance matrix \\[\\mathbf{\\Sigma} = I^{ -1 }\\] If slope of \\(-LL\\) is steep near the selection \\(\\Rightarrow\\) More confidence in the selection Model parameter uncertainty by: Assume join lognormal distribution for the parameters and use the correlation from \\(\\mathbf{\\Sigma}\\) from the MLE e.g. for Gamma, we might we’ll have a mean and \\(\\sigma\\) for \\(\\alpha\\) and \\(\\gamma\\) and correlation between \\(\\ln(\\alpha)\\) and \\(\\ln(\\beta)\\) A new set of parameters are selection for each iterations in the simulation Joint LogNormal distribution is selected (over joint normal) because: Eliminates negative losses Parameters estimates themselves are heavy tailed for heavy tailed distribution like Pareto e.g. \\(\\alpha\\) in simple Pareto \\(F(x) = 1 - \\left( \\frac{\\theta}{x} \\right)^{\\alpha}\\) follows inverse gamma, which is similar to LogNormal Results from simulations on small data sets showed that joint lognormal is reasonable "],
["model-risk.html", "23.5 Model Risk", " 23.5 Model Risk When considering different distributions, need to adjust the log likelihood with penalty for the number of parameters Hannan-Quinn Information Criterion (HQIC) is recommended because it is a compromise of other information criteria which add large or smaller penalties for # of parameter Create a pool of distn that are consider reasonable: Randomly select a mean for the parameters and a \\(\\mathbf{\\Sigma}\\) from the pool of distn Randomly draw the parameters based on the selected distn For each claim that is simulated, draw from the distribution with parameters from (2) "],
["projection-models.html", "23.6 Projection Models", " 23.6 Projection Models The form of the model is very important in measuring variability e.g. simple trend vs time series; expected parameters vs pool of distn for those parameters Use common sense to ensure model is structurally consistent with the underlying process Risk modeling we are more focused on the spread of potential outcomes instead of the best estimate Selecting models using parsimony will lead to unrealistically stable results Add flexibility (e.g. additional parameters) transfer assumptions from the structure to the parameters and allow the risk model reflect the uncertainty in the assumptions "],
["conclusion.html", "23.7 Conclusion", " 23.7 Conclusion Parameter risk is a key source of variability, especially for large companies Projection risk, estimation risk, model risk can all be quantified and applied in a simulation model -->"]
]
