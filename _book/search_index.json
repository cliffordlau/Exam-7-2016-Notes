[
["testing-the-assumptions-of-age-to-age-factors-g-venter.html", "Chapter 5 Testing the Assumptions of Age-to-Age Factors - G. Venter", " Chapter 5 Testing the Assumptions of Age-to-Age Factors - G. Venter Standards used in this paper The \\(n\\) for this paper excludes the first column Coefficient \\(&gt; 2 \\sigma\\) is significant Know the adj SSE, AIC and BIC Know the 6 implications Statistical significance of \\(f(d)\\) Is there a better estimate for \\(q\\) than \\(f \\times c\\) Number of parameters (Table 5.3) BF parameters (Table 5.4) Check residuals against \\(c(w,d)\\) Stability of \\(f(d)\\) down the column No correlation among columns Know the calculation for test No particularly high or low diagonals "],
["definitions-and-assumptions.html", "5.1 Definitions and Assumptions", " 5.1 Definitions and Assumptions Table 5.1: Tables of Definitions Venter Notations Definitions Mack Notations (??) \\(w\\) AYs \\(i\\) \\(d\\) Dev period; \\(d=0\\) is age @ end of year 1 \\(k\\) \\(c(w,d)\\) Cumulative losses for AY \\(w\\) age \\(d\\) \\(c_{i,k}\\) \\(c(w,\\infty)\\) Ultimate losses for AY \\(w\\) \\(c_{i,I}\\) \\(q(w, d+1)\\) Incremental losses for AY \\(w\\) age \\(d\\) to \\(d+1\\) \\(f(d)\\) Col parameters; (LDF - 1); applies to whole col \\(f_k - 1\\) \\(F(d)\\) LDF to ultimate that applies to \\(c(w,d)\\) \\(h(w)\\) Row parameters; applies to whole row 5.1.1 Mack’s Chainladder Assumptions Same assumptions as the Mack 1994 but stated in Venter’s terminology Proposition 5.1 (Mack Assumption 1) \\[\\mathrm{E}[q(w,d+1) \\mid \\text{Data to } w+d] = f(d) \\times c(w,d)\\] Remark. Here \\(f(d)\\) is LDF - 1 Expected incremental development is \\(\\propto\\) reported losses See also (Prop ??) from Mack (1994) Proposition 5.2 (Mack Assumption 2) \\[c(w,d) \\perp\\!\\!\\!\\!\\perp c(v,g) \\:\\:\\:\\: \\forall \\: d,g,v,w \\:\\:\\:\\: : \\:\\:\\:\\: v \\neq w\\] Remark. Losses not in the same row are independent of each other See also (Prop ??) from Mack (1994) Proposition 5.3 (Mack Assumption 3) \\[\\mathrm{Var}[q(w,d) \\mid \\text{Data to } w+d] = a_{fun}\\big(d,c(w,d)\\big)\\] Remark. Variance of incremental losses depends only on: Cumulative losses reported to date \\(c(w,d)\\) Age of the AY \\(d\\) (Does not vary by AY down the column) Different \\(a_{fun}(\\cdots)\\) leads to different \\(\\hat{f}(d)\\) estimate See also (Prop ??) from Mack (1994) 5.1.2 Variance Assumptions (for Chainladder) Same as shown in Mack 1994 Table ?? Table 5.2: Relationships between weight, variance and residual (Venter) Weight Description Variance \\(a_{fun}\\big(d,c(w,d)\\big)\\) LDF - 1 \\(f(d)\\) 1 Simple Average \\(k(d)c(w,d)^2\\) \\(\\dfrac{\\sum_w 1 \\frac{q(w,d+1)}{c(w,d)}}{\\sum_w 1}\\) \\(c(w,d)\\) Weighted Average \\(k(d)c(w,d)\\) \\(\\dfrac{\\sum_w c(w,d) \\frac{q(w,d+1)}{c(w,d)}}{\\sum_w c(w,d)}\\) \\(c(w,d)^2\\) Least Square \\(k(d)\\) \\(\\dfrac{\\sum_w c(w,d)^2 \\frac{q(w,d+1)}{c(w,d)}}{\\sum_w c(w,d)^2}\\) \\(c(w,\\infty) = F(d)c(w,d)\\) \\(F(d) = \\prod_{s \\geq d} (1 + f(s))\\) Recall \\(\\dfrac{q(w,d+1)}{c(w,d)}\\) are the empirical LDF - 1 \\(\\mathrm{E}[q(w,d+1)] = f(d)c(w,d)\\) \\(n = \\sum \\limits_{i=1}^{m-1} i = \\dfrac{m(m-1)}{2}\\) = predicted data point? \\(p=m-1\\) since we dont’ predict the first column \\(m =\\) dimension "],
["testable-implications.html", "5.2 6 Testable Implications", " 5.2 6 Testable Implications 6 Testable Implications Statistical significance of \\(f(d)\\) Is there a better estimate for \\(q\\) than \\(f \\times c\\) Check residuals against \\(c(w,d)\\) Stability of \\(f(d)\\) down the column No correlation among columns No particularly high or low diagonals 5.2.1 Goodness of Fit Measurement Compare different fit of the models based on adjusted \\(SSE\\) (actual vs projected excluding 1st column) Adjusted SSE \\[\\begin{equation} \\dfrac{SSE}{(n-p^2)} \\tag{5.1} \\end{equation}\\] Akaike Information Criterion \\[\\begin{equation} AIC \\approx SSE \\times e^{2p/n} \\tag{5.2} \\end{equation}\\] Bayesian Information Criterion \\[\\begin{equation} BIC \\approx SSE \\times n^{p/n} \\tag{5.3} \\end{equation}\\] Remark. \\(n =\\) # of predicted data points EXCLUDING 1st column Exclude because when we do reserving we don’t predict anything from the first column Usually the triangle excluding the first column \\(p =\\) # of parameters \\(SSE = \\sum (A - E)^2\\) Here you exclude the first column when calculating the difference Venter use the adjusted SSE as the AIC can be too permissive of over parameterization for large data sets 5.2.2 Implication 1: Significance of Factors Check if the parameter coefficient is \\(&gt; 2 \\sigma\\) for 95% sure that the parameters are \\(\\neq 0\\) Can do \\(1.65 \\sigma\\) for 90% confidence Remember \\(f(d)\\) is LDF - 1 LDFs tend to fail towards the tail 5.2.3 Implication 2: Superiority of Alternative Emergence Patterns If an alternative emergence pattern provides a better explanation of the triangle, maybe it should be used Table 5.3: Alternative emergerence pattern on a \\(m \\times m\\) triangle Emergence Patterns # of Parameters Comments \\(\\mathrm{E}[q(w,d+1) \\mid \\text{Data to }w+d] = f(d) c(w,d)\\) \\(m - 1\\) e.g. Chainladder \\(\\mathrm{E}[q(w,d+1) \\mid \\text{Data to }w+d] = f(d) c(w,d) + g(d)\\) \\(2m - 2\\) e.g. Least Squares \\(\\mathrm{E}[q(w,d) \\mid \\text{Data to }w+d] = f(d)h(w)\\) \\(2m-2\\) e.g. BF \\(\\mathrm{E}[q(w,d) \\mid \\text{Data to }w+d] = f(d)h\\) \\(m-1\\) e.g. Cape Cod Remark. \\(f(d) c(w,d) + g(d)\\) Often significant in forecasting age 1 Remark. \\(f(d)h(w)\\) Here \\(f(d)\\) is related to the % of losses emerged in period \\(d\\) Not LDF -1 \\(h(w)\\) can be think of as an estimate of ultimate losses for AY \\(w\\) Like an a-priori The -2 for the BF is due to \\(f(0)\\) and constant If BF is better \\(\\Rightarrow\\) Loss emergence is more accurately represented as fluctuating around a proportion of expected ultimate losses (rather than proportion of reported losses) Cape Cod works when the loss ratio is stable (stable book of business) Use \\(h(w) = h \\times Premium(w)\\), so we only need stable ELR Can further reduce parameters by combining some row and column parameters 5.2.3.1 Variance Assumptions: Alternative Emergence Pattern Minimize sum of squared error for the optimal parameters: e.g. error term for BF: \\(\\varepsilon(w,d) = q(w,d) - f(d)h(w)\\) Different variance assumption for \\(\\varepsilon\\) \\(\\Rightarrow\\) different parameters \\(\\mathrm{Var}(\\varepsilon) = f^p h^q\\) \\(p\\) &amp; \\(q\\) typically in (0,1,2) Weights will be \\(\\dfrac{1}{f^p h^q}\\) (inversely proportional to variance) \\(f(d)\\) = weighted average of \\(\\frac{q}{h}\\) \\(h(w)\\) = weighted average of \\(\\frac{q}{f}\\) Table 5.4: Variance and parameters for various form of \\(\\mathrm{E}[q(w,d) \\mid \\text{Data to }w+d] = f(d)h(w)\\) Method \\(\\mathbf{\\mathrm{Var}(q)}\\) \\(\\mathbf{f(d)}\\): Col Parameters \\(\\mathbf{h(w)}\\): Row Parameters BF (Constant Var, Least Square) \\(a(d); p=q=0\\) \\(f(d) = \\dfrac{\\sum_w h^2 \\frac{q}{h}}{\\sum_w h^2}\\) \\(h(w) = \\dfrac{\\sum_d f^2 \\frac{q}{f}}{\\sum_d f^2}\\) Cape Cod \\(a(d); p=q=0\\) \\(f(d) = \\dfrac{\\sum_w h^2 \\frac{q}{h}}{\\sum_w h^2}\\) \\(h = \\dfrac{\\sum_\\Delta f^2 \\frac{q}{f}}{\\sum_\\Delta f^2}\\) BF (Var \\(\\propto\\) \\(fh\\)) \\(a(d) \\cdot f \\cdot h; p=q=1\\) \\(f^2(d) = \\dfrac{\\sum_w h (\\frac{q}{h})^2}{\\sum_w h}\\) \\(h^2(w) = \\dfrac{\\sum_d f (\\frac{q}{f})^2}{\\sum_d f}\\) \\(f(d)\\) is % losses paid @ \\(d\\) Estimate by \\(\\frac{q}{h}\\) \\(h(w)\\) is estimate of ultimate losses Estimate by \\(\\frac{q}{f}\\) \\(f(d)\\) \\(\\sum \\downarrow\\); \\(h(w)\\) \\(\\sum \\rightarrow\\) (for the constant var BF) Need to seed one of them and iterate until convergence Use the above to estimate the parameters and then calculate the unpaid When combining parameters, don’t count the \\(f(0)\\) and always subtract 1 5.2.4 Implication 3: Linearity The forecast incremental losses doesn’t have to be linear Test for linearity to make sure the residuals are not a sequence of positive then negative and vice versa 5.2.5 Implication 4: Stability Look at empirical LDFs \\(f(d)\\) down a column Use the entire history if factors are stable Take more recent average if unstable or follow a trend 5.2.6 Implication 5: No Correlation on Columns Calculate Pearson correlation for every pair of columns with at least 3 LDFs This is a test on the LDFs Test with only 2 LDFs will either be 1 or -1 Correlation \\(r = \\dfrac{\\sum \\tilde{x} \\tilde{y}}{\\sqrt{\\sum \\tilde{x}^2\\sum \\tilde{y}^2}}\\) \\(\\tilde{x} = x - \\bar{x}\\) \\(\\tilde{y} = y - \\bar{y}\\) Test statistics: \\(T = r \\sqrt{ \\dfrac{n-2}{1-r^2} }\\) \\(T \\sim t_{n-2}\\) Look up the t-value from table for 90% If the absolute value of \\(T &lt;\\) table value \\(\\Rightarrow\\) Not correlated Perform test for all columns (with 3 or more LDFs pair) Correlations within the triangle if more than \\(0.1 m + \\sqrt{m}\\) pairs are correlated m = # of pair tested 5.2.7 Implication 6: No High of Low Diagonals Run regression that includes a variable for each diagonal Each \\(q(w,d)\\) is regressed against the cumulative losses at the prior period + dummy variable for which diagonal it is in \\(q(w,d) ~ c(w,d-1) + diagonal_{year}\\) If diagonal significatly high or low \\(\\Rightarrow\\) Dummy variable should have a statistically significant coefficient Same criteria where it is significant if coefficient is double the \\(\\sigma\\) Deficiceny of this method is that the diagonal effect is additive More likely to see multiplicative impact. e.g. from inflation This can be implement with a regression on the logarithm of the losses 5.2.7.1 Diagonal Trend as Inflation Model \\(q(w,d)\\) with a diagonal parameter \\(w+d\\) \\(\\mathrm{E}[q(w,d)] = f(d)h(w)g(w+d)\\) Model constant CY trend to reduce the parameters: \\(g(w+d) = (1+j)^{w+d}\\) "],
["past-exam-questions.html", "5.3 Past Exam Questions", " 5.3 Past Exam Questions Haven’t done TIA practice questions Concepts 2011 #4: Implication 1 2012 #5: Mack assumptions Implication Tests 2014 #4: Implication 5 correlation tests 2015 #5: Implication 5 correlation tests 5.3.1 Question Highlights n/a -->"]
]
